{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGAN1mYy9Xzr"
      },
      "source": [
        "# Fine-tune dots.ocr for Custom OCR Tasks\n",
        "\n",
        "This notebook shows how to fine-tune the dots.ocr model for custom OCR tasks on Google Colab.\n",
        "\n",
        "> **Note:** This notebook makes use of wjbmattingly's [dots.ocr training repo](https://github.com/wjbmattingly/dots.ocr).  \n",
        "\n",
        "## What is in this notebook:\n",
        "- Autolabel images using the base dots.ocr model\n",
        "- Prepare training data from your custom images\n",
        "- Finetune the model for better OCR on your specific content\n",
        "- Test and evaluate your finetuned model\n",
        "\n",
        "## Requirements:\n",
        "- A100/L4 GPU recommended\n",
        "- Images you want to train on (upload to Google Drive)\n",
        "\n",
        "## Workflow:\n",
        "1. Setup - Install dependencies and download base model\n",
        "2. Auto-label - Generate initial OCR predictions (skip if you have prepared data)\n",
        "3. Correct - Manually fix the generated labels (skip if you have prepared data)\n",
        "4. Train- Finetune the model on your corrected data\n",
        "- GPU: T4, L4, A100, or similar (T4 compatible!)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1TgYIuAfdzhU"
      },
      "outputs": [],
      "source": [
        "## Environment Setup\n",
        "\n",
        "import os\n",
        "import subprocess\n",
        "\n",
        "# Set memory allocation for better GPU usage\n",
        "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
        "\n",
        "# Check GPU availability\n",
        "print(\"Checking GPU...\")\n",
        "!nvidia-smi\n",
        "\n",
        "# Clone repository\n",
        "if not os.path.exists(\"dots.ocr\"):\n",
        "    !git clone https://github.com/knightofcookies/dots.ocr.git\n",
        "\n",
        "%cd dots.ocr\n",
        "\n",
        "# Install base dependencies first\n",
        "!pip install -q -r requirements.txt\n",
        "\n",
        "# Install training requirements (skip flash-attn for now, will install conditionally)\n",
        "!pip install -q torch>=2.0.0 transformers>=4.37.0 accelerate>=0.25.0 datasets>=2.16.0\n",
        "!pip install -q peft>=0.8.0 wandb Pillow>=8.0.0 tqdm qwen-vl-utils\n",
        "!pip install -q deepspeed bitsandbytes\n",
        "\n",
        "# Detect GPU and install flash-attn only if supported\n",
        "import torch\n",
        "if torch.cuda.is_available():\n",
        "    capability = torch.cuda.get_device_capability(0)\n",
        "    compute = float(f'{capability[0]}.{capability[1]}')\n",
        "    gpu_name = torch.cuda.get_device_name(0)\n",
        "    print(f'\\nDetected GPU: {gpu_name}')\n",
        "    print(f'Compute Capability: {compute}')\n",
        "    \n",
        "    if compute >= 8.0:\n",
        "        print('Flash Attention 2 is supported - installing...')\n",
        "        !pip install -q flash-attn --no-build-isolation\n",
        "    else:\n",
        "        print('⚠️  Flash Attention 2 NOT supported on this GPU (requires compute capability >= 8.0)')\n",
        "        print('Training will use standard PyTorch attention (slower but compatible with T4)')\n",
        "        print('This is fine for fine-tuning! Just expect longer training times.')\n",
        "\n",
        "!pip install -e .\n",
        "\n",
        "# Download base model weights (~6GB)\n",
        "!python tools/download_model.py\n",
        "\n",
        "print(\"\\n✅ Setup complete\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gjFRcRx5d7Gg",
        "outputId": "6c993239-f86b-445e-92f2-d70fce65ee7c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "Images directory: /content/drive/MyDrive/images\n",
            "Autolabel directory: /content/autolabel\n"
          ]
        }
      ],
      "source": [
        "## Mount Google Drive\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "# Set up paths\n",
        "IMAGES_DIR = \"/content/drive/MyDrive/temp/my_pdf_pages/\"  # Images\n",
        "AUTOLABEL_DIR = \"/content/autolabel\"  # Autolabeled results\n",
        "\n",
        "print(f\"Images directory: {IMAGES_DIR}\")\n",
        "print(f\"Autolabel directory: {AUTOLABEL_DIR}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHMwNlUBeIGR"
      },
      "source": [
        "## Upload Your Images\n",
        "\n",
        "**Before proceeding:**\n",
        "1. Go to Google Drive and create a folder called 'images' in your My Drive\n",
        "2. Upload the images you want to train on\n",
        "3. Supported formats: .jpg, .jpeg, .png, .pdf\n",
        "\n",
        "\n",
        "\n",
        "Note: If you already have prepared training data, skip to the training section.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YocksYx5ePvU"
      },
      "outputs": [],
      "source": [
        "## Autolabel Your Images\n",
        "\n",
        "import os\n",
        "import glob\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Create output directory\n",
        "os.makedirs(AUTOLABEL_DIR, exist_ok=True)\n",
        "\n",
        "# Find all image files\n",
        "image_files = []\n",
        "for ext in [\"*.jpg\", \"*.jpeg\", \"*.png\", \"*.pdf\"]:\n",
        "    image_files.extend(glob.glob(os.path.join(IMAGES_DIR, ext)))\n",
        "\n",
        "print(f\"Found {len(image_files)} images to process\")\n",
        "\n",
        "if len(image_files) == 0:\n",
        "    print(\"No images found! Please upload images to Google Drive first.\")\n",
        "    print(f\"Expected location: {IMAGES_DIR}\")\n",
        "else:\n",
        "    # Process each image\n",
        "    successful = 0\n",
        "    failed = 0\n",
        "\n",
        "    for img_path in tqdm(image_files, desc=\"Autolabeling\"):\n",
        "        try:\n",
        "            !python -m dots_ocr.parser \"{img_path}\" --output \"{AUTOLABEL_DIR}\" --prompt \"prompt_ocr\" --use_hf true\n",
        "            successful += 1\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to process {os.path.basename(img_path)}: {e}\")\n",
        "            failed += 1\n",
        "\n",
        "    print(f\"\\nAuto-labeling completed!\")\n",
        "    print(f\"Successful: {successful}\")\n",
        "    print(f\"Failed: {failed}\")\n",
        "    print(f\"Results saved to: {AUTOLABEL_DIR}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lB7o4kxt-dbN"
      },
      "source": [
        "## Manual Correction\n",
        "\n",
        "\n",
        "### How to correct your labels:\n",
        "\n",
        "Since autolabel results are saved directly to your Google Drive, you can edit them there:\n",
        "\n",
        "1. Open Google Drive and navigate to 'MyDrive/autolabel'\n",
        "2. For each sample folder, open the '.md' file\n",
        "3. Edit the text to correct any OCR errors\n",
        "4. Save the file directly in Google Drive\n",
        "\n",
        "That's it! No need to download/upload. The training script will read the corrected files from Drive.\n",
        "\n",
        "Skip this section if you already have prepared training data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9L8c-O33-g4Q"
      },
      "source": [
        "## Prepare Training Data\n",
        "\n",
        "Expected data format: Your data should be in '/content/drive/MyDrive/autolabel/' with this structure:\n",
        "\n",
        "    autolabel/\n",
        "    ├── sample1/\n",
        "    │   ├── sample1.jpg\n",
        "    │   ├── sample1.md\n",
        "    │   └── sample1.json\n",
        "    ├── sample2/\n",
        "    │   ├── sample2.jpg\n",
        "    │   ├── sample2.md\n",
        "    │   └── sample2.json\n",
        "    └── ...\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DEJP7Naz_T-T"
      },
      "source": [
        "### **Training JSONL Format**\n",
        "\n",
        "Your corrected data will be converted into a `.jsonl` file for training (`train_ocr_resized.jsonl`).  \n",
        "Each line in this file is one training sample in JSON format.\n",
        "\n",
        "**Expected JSONL structure:**\n",
        "\n",
        "```json\n",
        "{\"messages\":[\n",
        "  {\"role\":\"user\",\"content\":[\n",
        "    {\"type\":\"image\",\"image\":\"/content/resized_images/sample1.jpg\"},\n",
        "    {\"type\":\"text\",\"text\":\"prompt_ocr\"}\n",
        "  ]},\n",
        "  {\"role\":\"assistant\",\"content\":\"This is the corrected OCR text for sample 1.\"}\n",
        "]}\n",
        "{\"messages\":[\n",
        "  {\"role\":\"user\",\"content\":[\n",
        "    {\"type\":\"image\",\"image\":\"/content/resized_images/sample2.jpg\"},\n",
        "    {\"type\":\"text\",\"text\":\"prompt_ocr\"}\n",
        "  ]},\n",
        "  {\"role\":\"assistant\",\"content\":\"This is the corrected OCR text for sample 2.\"}\n",
        "]}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TYuzMOy9eqsB"
      },
      "outputs": [],
      "source": [
        "## 7. Finetune the Model\n",
        "\n",
        "TRAINING_JSONL = \"/content/drive/MyDrive/train_ocr_resized.jsonl\"\n",
        "\n",
        "# Check if training data exists\n",
        "if not os.path.exists(TRAINING_JSONL):\n",
        "    print(f\"Training data not found: {TRAINING_JSONL}\")\n",
        "    print(\"Please run the previous step to prepare training data first.\")\n",
        "else:\n",
        "    print(\"Starting finetuning...\")\n",
        "    \n",
        "    # Detect GPU for Flash Attention compatibility\n",
        "    import torch\n",
        "    flash_attn_flag = \"\"\n",
        "    if torch.cuda.is_available():\n",
        "        capability = torch.cuda.get_device_capability(0)\n",
        "        compute = float(f'{capability[0]}.{capability[1]}')\n",
        "        if compute < 8.0:\n",
        "            print(f\"⚠️  Detected GPU with compute capability {compute} (T4 or older)\")\n",
        "            print(\"Flash Attention will be automatically disabled for compatibility.\")\n",
        "            # No need to add --no_flash_attention, the script auto-detects\n",
        "    \n",
        "    # Train the model\n",
        "    # Note: Flash Attention is auto-detected. Use --use_flash_attention to force enable\n",
        "    # or --no_flash_attention to force disable\n",
        "    !python train_simple.py \\\n",
        "        --data \"{TRAINING_JSONL}\" \\\n",
        "        --epochs 15 \\\n",
        "        --batch_size 1 \\\n",
        "        --learning_rate 3e-4 \\\n",
        "        --max_length 1024 \\\n",
        "        --gradient_checkpointing \\\n",
        "        --output_dir \"/content/local_checkpoints\"\n",
        "\n",
        "    print(\"Training completed\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "czCCIYTgetGd"
      },
      "outputs": [],
      "source": [
        "## 7. Finetune the Model\n",
        "\n",
        "TRAINING_JSONL = \"/content/drive/MyDrive/train_ocr_resized.jsonl\"\n",
        "\n",
        "# Check if training data exists\n",
        "if not os.path.exists(TRAINING_JSONL):\n",
        "    print(f\"Training data not found: {TRAINING_JSONL}\")\n",
        "    print(\"Please run the previous step to prepare training data first.\")\n",
        "else:\n",
        "    print(\"Starting finetuning...\")\n",
        "\n",
        "    # Train the model\n",
        "    !python train_simple.py \\\n",
        "        --data \"{TRAINING_JSONL}\" \\\n",
        "        --epochs 15 \\\n",
        "        --batch_size 1 \\\n",
        "        --learning_rate 3e-4 \\\n",
        "        --max_length 1024 \\\n",
        "        --gradient_checkpointing \\\n",
        "        --output_dir \"/content/local_checkpoints\"\n",
        "\n",
        "    print(\"Training completed\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a5uBbGYEe12X"
      },
      "outputs": [],
      "source": [
        "## 8. Setup Finetuned Model\n",
        "\n",
        "print(\"Copying configuration files...\")\n",
        "\n",
        "# Ensure we have base model files\n",
        "!python tools/download_model.py\n",
        "\n",
        "# Copy missing configuration files from base model\n",
        "!cp ./weights/DotsOCR/configuration_dots.py /content/local_checkpoints/final_model/\n",
        "!cp ./weights/DotsOCR/modeling_*.py /content/local_checkpoints/final_model/\n",
        "\n",
        "print(\"Replacing base model with finetuned model...\")\n",
        "!rm -rf ./weights/DotsOCR\n",
        "!cp -r /content/local_checkpoints/final_model ./weights/DotsOCR\n",
        "\n",
        "print(\"Verifying model setup...\")\n",
        "!python -c \"import json; json.load(open('./weights/DotsOCR/config.json')); print('Model setup complete')\"\n",
        "\n",
        "print(\"\\nYour finetuned model is ready for inference\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UUdz9uoImqrl"
      },
      "outputs": [],
      "source": [
        "from PIL import Image, ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "def sanitize(img_path, dst_dir):\n",
        "    try:\n",
        "        with Image.open(img_path) as im:\n",
        "            im = im.convert(\"RGB\")\n",
        "            w, h = im.size\n",
        "            if max(w, h) > 1024:\n",
        "                s = 1024 / max(w, h)\n",
        "                im = im.resize((int(w*s), int(h*s)), Image.Resampling.LANCZOS)\n",
        "            clean_path = os.path.join(dst_dir, os.path.basename(img_path))\n",
        "            im.save(clean_path, format=\"JPEG\", quality=92, optimize=True)\n",
        "            return clean_path\n",
        "    except Exception as e:\n",
        "        print(f\"[skip bad image] {img_path} -> {e}\")\n",
        "        return None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oE8trhvre7Lg"
      },
      "outputs": [],
      "source": [
        "# Test OCR\n",
        "# Set your file path here:\n",
        "IMAGE_PATH = \"/content/resized_images/SCR-20250715-iho.jpg\"\n",
        "\n",
        "from dots_ocr.parser import DotsOCRParser\n",
        "import os\n",
        "\n",
        "parser = DotsOCRParser(use_hf=True, max_completion_tokens=128)\n",
        "result = parser.parse_file(IMAGE_PATH, prompt_mode=\"prompt_ocr\")\n",
        "\n",
        "if not result:\n",
        "    print(\"[no result]\")\n",
        "else:\n",
        "    info = result[0]\n",
        "    text = None\n",
        "\n",
        "    md_path = info.get(\"md_content_path\")\n",
        "    if md_path and os.path.exists(md_path):\n",
        "        with open(md_path, \"r\", encoding=\"utf-8\") as f:\n",
        "            text = f.read()\n",
        "\n",
        "    if text is None and isinstance(info.get(\"content\"), str):\n",
        "        text = info[\"content\"]\n",
        "\n",
        "    print(text or \"[empty]\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PTpzUStufCYs"
      },
      "outputs": [],
      "source": [
        "## 10. Save the Fine-tuned Model\n",
        "print(\"Saving fine-tuned model to Google Drive...\")\n",
        "\n",
        "!cp -r /content/local_checkpoints/final_model /content/drive/MyDrive/dots_ocr_finetuned\n",
        "\n",
        "print(\"\\nFine-tuned model saved to Google Drive\")\n",
        "print(\"Location: /content/drive/MyDrive/dots_ocr_finetuned\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c51dXgzW8bZj"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "### Resources:\n",
        "- [dots.ocr GitHub](https://github.com/rednote-hilab/dots.ocr)\n",
        "- [Training Documentation](https://github.com/wjbmattingly/dots.ocr/blob/main/README_model_training.md)\n",
        "\n",
        "Happy training!"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
